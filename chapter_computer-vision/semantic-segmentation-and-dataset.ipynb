{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语义分割和数据集\n",
    "\n",
    "图片分类关心识别图片里面的主要物体，物体识别则进一步找出图片的多个物体以及它们的方形边界框。本小节我们将介绍语义分割（semantic segmentation），它在物体识别上更进一步的找出物体的精确边界框。换句话说，它识别图片中的每个像素属于哪类我们感兴趣的物体还是只是背景。下图演示猫和狗图片在语义分割中的标注。可以看到，跟物体识别相比，语义分割预测的边框更加精细。\n",
    "\n",
    "![ 语义分割的训练数据和标注。](../img/segmentation.svg)\n",
    "\n",
    "在计算机视觉里，还有两个跟语义分割相似的任务。一个是图片分割（image segmentation），它也是将像素划分到不同的类。不同的是，语义分割里我们赋予像素语义信息，例如属于猫、狗或者背景。而图片分割则通常根据像素本身之间的相似性，它训练时不需要像素标注信息，其预测结果也不能保证有语义性。例如图片分割可能将上图中的狗划分成两个区域，其中一个嘴巴和眼睛，其颜色以黑色为主，另一个是身体其余部分，其主色调是黄色。\n",
    "\n",
    "另一个应用是实例分割（instance segementation），它不仅需要知道每个像素的语义，即属于那一类物体，还需要进一步区分物体实例。例如如果图片中有两只狗，那么对于预测为对应狗的像素是属于地一只狗还是第二只。\n",
    "\n",
    "## Pascal VOC 语义分割数据集\n",
    "\n",
    "下面我们使用一个常用的语义分割数据集\n",
    "[Pascal VOC2012](http://host.robots.ox.ac.uk/pascal/VOC/voc2012/) 来介绍这个应用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import gluonbook as gb\n",
    "from mxnet import gluon, image, nd\n",
    "from mxnet.gluon import data as gdata, utils as gutils\n",
    "import os\n",
    "import tarfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们首先下载这个数据集到 `../data` 下。压缩包大小是 2GB，下载需要一定时间。解压之后这个数据集将会放置在 `../data/VOCdevkit/VOC2012` 下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = '../data'\n",
    "voc_dir = os.path.join(data_dir, 'VOCdevkit/VOC2012')\n",
    "url = ('http://host.robots.ox.ac.uk/pascal/VOC/voc2012'\n",
    "       '/VOCtrainval_11-May-2012.tar')\n",
    "sha1 = '4e443f8a2eca6b1dac8a6c57641b67dd40621a49'\n",
    "\n",
    "fname = gutils.download(url, data_dir, sha1_hash=sha1)\n",
    "with tarfile.open(fname, 'r') as f:\n",
    "    f.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 `ImageSets/Segmentation` 下有文本文件指定哪些样本用来训练，哪些用来测试。样本图片放置在 `JPEGImages` 下，标注则放在 `SegmentationClass` 下。这里标注也是图片格式，图片大小与对应的样本图片一致，其中颜色相同的像素属于同一个类。\n",
    "\n",
    "下面定义函数将图片和标注全部读进内存。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [],
   "source": [
    "def read_voc_images(root=voc_dir, train=True):\n",
    "    txt_fname = '%s/ImageSets/Segmentation/%s' % (\n",
    "        root, 'train.txt' if train else 'val.txt')\n",
    "    with open(txt_fname, 'r') as f:\n",
    "        images = f.read().split()\n",
    "    data, label = [None] * len(images), [None] * len(images)\n",
    "    for i, fname in enumerate(images):\n",
    "        data[i] = image.imread('%s/JPEGImages/%s.jpg' % (root, fname))\n",
    "        label[i] = image.imread('%s/SegmentationClass/%s.png' % (root, fname))\n",
    "    return data, label\n",
    "\n",
    "train_images, train_labels = read_voc_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们画出前面五张图片和它们对应的标注。在标注，白色代表边框黑色代表背景，其他不同的颜色对应不同物体类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [],
   "source": [
    "n = 5\n",
    "imgs = train_images[0:n] + train_labels[0:n]\n",
    "gb.show_images(imgs, 2, n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来我们列出标注中每个 RGB 颜色值对应的类别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    }
   },
   "outputs": [],
   "source": [
    "voc_colormap = [[0, 0, 0], [128, 0, 0], [0, 128, 0], [128, 128, 0],\n",
    "                [0, 0, 128], [128, 0, 128], [0, 128, 128], [128, 128, 128],\n",
    "                [64, 0, 0], [192, 0, 0], [64, 128, 0], [192, 128, 0],\n",
    "                [64, 0, 128], [192, 0, 128], [64, 128, 128], [192, 128, 128],\n",
    "                [0, 64, 0], [128, 64, 0], [0, 192, 0], [128, 192, 0],\n",
    "                [0, 64, 128]]\n",
    "\n",
    "voc_classes = ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle',\n",
    "               'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog',\n",
    "               'horse', 'motorbike', 'person', 'potted plant', 'sheep',\n",
    "               'sofa', 'train', 'tv/monitor']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这样给定一个标号图片，我们就可以将每个像素对应的物体标号找出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    }
   },
   "outputs": [],
   "source": [
    "colormap2label = nd.zeros(256**3)\n",
    "for i, cm in enumerate(voc_colormap):\n",
    "    colormap2label[(cm[0] * 256 + cm[1]) * 256 + cm[2]] = i\n",
    "\n",
    "def voc_label_indices(img):\n",
    "    data = img.astype('int32')\n",
    "    idx = (data[:,:,0] * 256 + data[:,:,1]) * 256 + data[:,:,2]\n",
    "    return colormap2label[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到第一张样本中飞机头部对应的标注里属于飞机的像素被标记成了 1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
       " [ 0.  0.  0.  0.  0.  0.  0.  1.  1.  1.]\n",
       " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  1.]\n",
       " [ 0.  0.  0.  0.  0.  1.  1.  1.  1.  1.]\n",
       " [ 0.  0.  0.  0.  0.  1.  1.  1.  1.  1.]\n",
       " [ 0.  0.  0.  0.  1.  1.  1.  1.  1.  1.]\n",
       " [ 0.  0.  0.  0.  0.  1.  1.  1.  1.  1.]\n",
       " [ 0.  0.  0.  0.  0.  1.  1.  1.  1.  1.]\n",
       " [ 0.  0.  0.  0.  0.  0.  1.  1.  1.  1.]\n",
       " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  1.]]\n",
       "<NDArray 10x10 @cpu(0)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = voc_label_indices(train_labels[0])\n",
    "y[105:115, 130:140]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理\n",
    "\n",
    "我们知道小批量训练需要输入图片的形状一致。之前我们通过图片缩放来得到同样形状的输入。但语义分割里，如果对样本图片进行缩放，那么重新映射每个像素对应的类别将变得困难，特别是对应物体边缘的像素。\n",
    "\n",
    "为了避免这个困难，这里我们将图片剪裁成固定大小而不是缩放。特别的，我们使用随机剪裁来附加图片增广。下面定义随机剪裁函数，其对样本图片和标注使用用样的剪裁。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "8"
    }
   },
   "outputs": [],
   "source": [
    "def rand_crop(data, label, height, width):\n",
    "    data, rect = image.random_crop(data, (width, height))\n",
    "    label = image.fixed_crop(label, *rect)\n",
    "    return data, label\n",
    "\n",
    "imgs = []\n",
    "for _ in range(n):\n",
    "    imgs += rand_crop(train_images[0], train_labels[0], 200, 300)\n",
    "gb.show_images(imgs[::2] + imgs[1::2], 2, n);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据读取\n",
    "\n",
    "下面我们定义 Gluon 可以使用的数据集类，它可以返回任意的第 $i$ 个样本图片和标号。除了随机剪裁外，这里我们将样本图片进行了归一化，同时过滤了小于剪裁尺寸的图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    }
   },
   "outputs": [],
   "source": [
    "class VOCSegDataset(gdata.Dataset):\n",
    "    def __init__(self, train, crop_size):\n",
    "        self.rgb_mean = nd.array([0.485, 0.456, 0.406])\n",
    "        self.rgb_std = nd.array([0.229, 0.224, 0.225])\n",
    "        self.crop_size = crop_size        \n",
    "        data, label = read_voc_images(train=train)\n",
    "        self.data = [self.normalize_image(im) for im in self.filter(data)]\n",
    "        self.label = self.filter(label)            \n",
    "        print('read ' + str(len(self.data)) + ' examples')\n",
    "        \n",
    "    def normalize_image(self, data):\n",
    "        return (data.astype('float32') / 255 - self.rgb_mean) / self.rgb_std\n",
    "    \n",
    "    def filter(self, images):\n",
    "        return [im for im in images if (\n",
    "            im.shape[0] >= self.crop_size[0] and\n",
    "            im.shape[1] >= self.crop_size[1])]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = rand_crop(self.data[idx], self.label[idx],\n",
    "                                *self.crop_size)\n",
    "        return data.transpose((2, 0, 1)), voc_label_indices(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们剪裁 $320\\times 480$ 图片来进行训练，我们可以查看训练和测试各保留了多少图片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1114 examples\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 1078 examples\n"
     ]
    }
   ],
   "source": [
    "output_shape = (320, 480)  # 高和宽。\n",
    "voc_train = VOCSegDataset(True, output_shape)\n",
    "voc_test = VOCSegDataset(False, output_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后定义批量读取，这里使用 4 个进程来加速读取（代码保存在 gluonbook 的 `load_data_pascal_voc` 函数里方便之后使用）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "11"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_iter = gdata.DataLoader(\n",
    "    voc_train, batch_size, shuffle=True, last_batch='discard', num_workers=4)\n",
    "test_iter = gdata.DataLoader(\n",
    "    voc_test, batch_size, last_batch='discard', num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印第一个批量可以看到，不同于图片分类和物体识别，这里的标签是一个三维的数组。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 3, 320, 480)\n",
      "(64, 320, 480)\n"
     ]
    }
   ],
   "source": [
    "for X, Y in train_iter:\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "* 语义分割识别图片中每个像素的类别。\n",
    "* 语义分割数据集中的标注由于跟跟样本图片有像素级的对应，使得其对应用图片变形类增广时有一定的限制。\n",
    "\n",
    "## 练习\n",
    "\n",
    "* 对比下有哪些图片分类上使用的图片增广比较难在语义分割上使用。\n",
    "\n",
    "## 扫码直达 [ 讨论区 ](https://discuss.gluon.ai/t/topic/7218)\n",
    "\n",
    "![](../img/qr_semantic-segmentation-and-dataset.svg)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}