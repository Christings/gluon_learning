{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一.Softmax回归\n",
    "    和线性回归不同，softmax 回归的输出单元从一个变成了多个，且引入了 softmax 运算使得输出更适合离散值的预测和训练。\n",
    "### 1.Softmax 回归模型\n",
    "    Softmax 回归跟线性回归一样将输入特征与权重做线性叠加。\n",
    "    与线性回归的一个主要不同在于，softmax 回归的输出值个数等于标签里的类别数。\n",
    "#### 1.1 Softmax运算\n",
    "分类问题需要得到离散的预测输出，一个简单的办法是将输出值 $o_i$ 当做预测类别是 i 的置信度，并将值最大的输出所对应的类作为预测输出，即输出 $argmax_io_i$。\n",
    "\n",
    "问题：\n",
    "    一方面，由于输出层的输出值的范围不确定，我们难以直观上判断这些值的意义。\n",
    "    另一方面，由于真实标签是离散值，这些离散值与不确定范围的输出值之间的误差难以衡量。\n",
    "    \n",
    "Softmax 运算符（softmax operator）解决了以上两个问题，通过下式将输出值变换成值为正且和为 1 的概率分布：\n",
    "\n",
    "$$\\hat{y}_1,\\hat{y}_2,\\hat{y}_3=\\text{softmax}(o_1,o_2,o_3)$$\n",
    "其中：$$ \\hat{y}_1 = \\frac{ \\exp(o_1)}{\\sum{i=1}^3 \\exp(o_i)},\\quad \\hat{y}_2 = \\frac{ \\exp(o_2)}{\\sum{i=1}^3 \\exp(o_i)},\\quad \\hat{y}_3 = \\frac{ \\exp(o_3)}{\\sum{i=1}^3 \\exp(o_i)}. $$\n",
    "\n",
    "注意:\n",
    "\n",
    "$$\\operatorname{argmax}_i o_i = \\operatorname{argmax}_i\\hat y_i,$$\n",
    "\n",
    "因此softmax运算不改变预测类别输出。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 二.SOftmax--从0开始实现"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
