{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二维卷积层\n",
    "\n",
    "卷积神经网络是指主要由卷积层（convolutional layer）组成的网络。因为它最常用来处理图片数据，其有高和宽两个空间维度（彩色图片的颜色通道维度将在之后小节讨论），所以最常用到的是二维卷积层。本小节本节我们将介绍简单形式的二维卷积层的是怎么工作的。\n",
    "\n",
    "## 二维相关运算符\n",
    "\n",
    "虽然卷积层得名于卷积运算符（convolution），但我们常用更加直观的相关运算符（correlation）来实现卷积层。一个二维相关运算符将一个二维核（kernel）数组作用在一个二维输入数据上来计算一个二维数组输出。下图演示了如何对一个高宽为 3 的输入 `X` 作用高宽为 2 的核 `K` 来计算输出 `Y`。\n",
    "\n",
    "![ 二维相关运算符，高亮了计算第一个输出元素所使用的输入和核数组元素。](../img/correlation.svg)\n",
    "\n",
    "可以看到输出 `Y` 的形状是 `(2, 2)`，且第一个元素是由 `X` 的左上的高宽为 2 的子数组与核数组按元素相乘后再相加得来。即 `Y[0, 0] = (X[0:2, 0:2] * K).sum()`，这里 `X`、`K` 和 `Y` 的类型都是 NDArray。接下来我们将这个高宽为 2 的窗口在 `X` 上向左滑动一列来计算 `Y` 的第二列第一个元素。以此类推计算得到所有结果。\n",
    "\n",
    "下面我们将上述过程实现在 `corr2d` 函数里，它接受 `X` 和 `K`，输出 `Y`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import gluonbook as gb\n",
    "from mxnet import autograd, nd\n",
    "from mxnet.gluon import nn\n",
    "\n",
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = nd.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i : i + h, j : j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造上图中的数据来测试实现的正确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 19.  25.]\n",
       " [ 37.  43.]]\n",
       "<NDArray 2x2 @cpu(0)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.array([[0, 1, 2], [3, 4, 5], [6, 7, 8]])\n",
    "K = nd.array([[0, 1], [2, 3]])\n",
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二维卷积层\n",
    "\n",
    "二维卷积层就是将输入和其维护的核数组，也称作卷积核，做相关运算，然后加上一个标量偏差来得到输出。它的模型参数包括了卷积核和标量偏差。在训练的时候，我们通常首先对卷积核进行随机初始化，然后不断迭代更新卷积核和偏差来拟合数据。\n",
    "\n",
    "下面的我们基于 `corr2d` 函数来实现一个自定义的二维卷积层。在初始化函数里我们声明 `weight` 和 `bias` 这两个模型参数，前向计算函数则是直接调用 `corr2d` 再加上偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "70"
    }
   },
   "outputs": [],
   "source": [
    "class Conv2D(nn.Block):\n",
    "    def __init__(self, kernel_size, **kwargs):\n",
    "        super(Conv2D, self).__init__(**kwargs)\n",
    "        self.weight = self.params.get('weight', shape=kernel_size)\n",
    "        self.bias = self.params.get('bias', shape=(1,))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return corr2d(x, self.weight.data()) + self.bias.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你也许会好奇既然称之为卷积层，为什么不使用卷积运算符呢？其实卷积运算的计算与二维相关运算类似，唯一的区别是反向的将核数组跟输入做乘法，即 `Y[0, 0] = (X[0:2, 0:2] * K[::-1, ::-1]).sum()`。但是因为在卷积层里 `K` 是学习而来的，所以不论是正向还是反向访问都可以。\n",
    "\n",
    "## 图片物体边缘检测\n",
    "\n",
    "下面我们来看一个应用卷积层的简单应用：检测图片中物体的边缘，即找到像素变化的位置。首先我们构造一张 $6\\times 8$ 的图，它中间 4 列为黑（0），其余为白（1）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "66"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 1.  1.  0.  0.  0.  0.  1.  1.]\n",
       " [ 1.  1.  0.  0.  0.  0.  1.  1.]\n",
       " [ 1.  1.  0.  0.  0.  0.  1.  1.]\n",
       " [ 1.  1.  0.  0.  0.  0.  1.  1.]\n",
       " [ 1.  1.  0.  0.  0.  0.  1.  1.]\n",
       " [ 1.  1.  0.  0.  0.  0.  1.  1.]]\n",
       "<NDArray 6x8 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = nd.ones((6, 8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们构造一个形状为 `(1, 2)` 的卷积核，使得其作用在相同的横向相邻元素上输出为 0，否则输出非 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "67"
    }
   },
   "outputs": [],
   "source": [
    "K = nd.array([[1, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对 `X` 作用我们设计的核 `K` 后可以发现，从白到黑的边缘我们检测成了 1，从黑到白则是 -1，其余全是 0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "69"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]\n",
       " [ 0.  1.  0.  0.  0. -1.  0.]]\n",
       "<NDArray 6x7 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里我们可以看到卷积层通过重复的使用 `K` 来有效的发掘局部空间特征。\n",
    "\n",
    "## 通过数据学习核数组\n",
    "\n",
    "最后我们来看一个例子，它使用前面的 `X` 和 `Y` 来学习我们构造的 `K`。我们首先构造一个卷积层，将其卷积核初始化成随机数组。然后在每一个迭代里，我们使用平方误差来比较 `Y` 和卷积层的输出，然后计算梯度来更新权重。\n",
    "\n",
    "虽然我们之前构造了 Conv2D 类，但由于 `corr2d` 使用了对单个元素赋值（`[i, j]=`）的操作会导致无法自动求导，下面我们使用 Gluon 提供的 Conv2D 类来实现这个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "83"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1, loss 4.949\n",
      "batch 3, loss 0.831\n",
      "batch 5, loss 0.140\n",
      "batch 7, loss 0.024\n",
      "batch 9, loss 0.004\n"
     ]
    }
   ],
   "source": [
    "# 构造一个输出通道是 1（将在后面小节介绍通道），核数组形状是 (1，2) 的二维卷积层。\n",
    "conv2d = nn.Conv2D(1, kernel_size=(1, 2))\n",
    "conv2d.initialize()\n",
    "\n",
    "# 二维卷积层使用 4 维输入输出，格式为（批量大小，通道数，高，宽），这里批量和通道均为 1。\n",
    "X = X.reshape((1, 1, 6, 8))\n",
    "Y = Y.reshape((1, 1, 6, 7))\n",
    "\n",
    "for i in range(10):\n",
    "    with autograd.record():\n",
    "        Y_hat = conv2d(X)\n",
    "        l = (Y_hat-Y) ** 2\n",
    "        if i % 2 == 1:\n",
    "            print('batch %d, loss %.3f' % (i, l.sum().asscalar()))\n",
    "    l.backward()\n",
    "    # 为了简单起见这里忽略了偏差。\n",
    "    conv2d.weight.data()[:] -= 3e-2 * conv2d.weight.grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到 10 次迭代后误差已经降到了一个比较小的值，现在来看一下学习到的核。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[ 0.98949999 -0.98737049]]\n",
       "<NDArray 1x2 @cpu(0)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data().reshape((1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看到学到的核与我们之前定义的 `K` 非常接近。\n",
    "\n",
    "## 小结\n",
    "\n",
    "- 二维卷积层的核心计算是二维相关运算。在最简单的形式下，它对二维输入数据和卷积核做相关运算然后加上偏差。\n",
    "- 我们可以设计卷积核来检测图片中的边缘，同时也可以通过数据来学习它。\n",
    "\n",
    "## 练习\n",
    "\n",
    "- 构造一个 `X`，它有水平方向的边缘，如何设计 `K` 来检测它？如果是对角方向的边缘呢？\n",
    "- 试着对我们构造的 `Conv2D` 进行自动求导，会有什么样的错误信息？\n",
    "- 在 Conv2D 的 `forward` 函数里，将 `corr2d` 替换成 `nd.Convolution` 使得其可以求导。\n",
    "- 试着将 conv2d 的核构造成 `(2, 2)`，会学出什么样的结果？\n",
    "- 如何通过变化输入和核的矩阵来将相关运算表示成一个矩阵乘法。\n",
    "- 如何构造一个全连接层来进行物体边缘检测？\n",
    "\n",
    "## 扫码直达 [ 讨论区 ](https://discuss.gluon.ai/t/topic/6314)\n",
    "\n",
    "![](../img/qr_conv-layer.svg)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}