{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 批量归一化的 Gluon 实现\n",
    "\n",
    "相比于前小节定义的 BatchNorm 类，`nn` 模块定义的 BatchNorm 使用更加简单。它不需要指定输出数据的维度和特征维的大小，这些都将通过延后初始化来获取。我们实现同前小节一样的批量归一化的 LeNet。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import gluonbook as gb\n",
    "from mxnet import nd, gluon, init\n",
    "from mxnet.gluon import loss as gloss, nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "net.add(\n",
    "    nn.Conv2D(6, kernel_size=5),\n",
    "    nn.BatchNorm(),\n",
    "    nn.Activation('sigmoid'),\n",
    "    nn.MaxPool2D(pool_size=2, strides=2),\n",
    "    nn.Conv2D(16, kernel_size=5),\n",
    "    nn.BatchNorm(),\n",
    "    nn.Activation('sigmoid'),\n",
    "    nn.MaxPool2D(pool_size=2, strides=2),\n",
    "    nn.Dense(120),\n",
    "    nn.BatchNorm(),\n",
    "    nn.Activation('sigmoid'),\n",
    "    nn.Dense(84),\n",
    "    nn.BatchNorm(),\n",
    "    nn.Activation('sigmoid'),\n",
    "    nn.Dense(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用同样的超参数进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on gpu(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.6671, train acc 0.762, test acc 0.851, time 2.2 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss 0.3965, train acc 0.857, test acc 0.857, time 1.9 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss 0.3442, train acc 0.875, test acc 0.878, time 2.0 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss 0.3198, train acc 0.884, test acc 0.874, time 2.0 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss 0.3001, train acc 0.890, test acc 0.874, time 2.0 sec\n"
     ]
    }
   ],
   "source": [
    "lr = 1.0\n",
    "num_epochs = 5\n",
    "batch_size = 256\n",
    "ctx = gb.try_gpu()\n",
    "net.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "train_iter, test_iter = gb.load_data_fashion_mnist(batch_size)\n",
    "gb.train_ch5(net, train_iter, test_iter, loss, batch_size, trainer, ctx,\n",
    "             num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "Gluon 提供的 BatchNorm 在使用上更加简单。\n",
    "\n",
    "## 练习\n",
    "\n",
    "* 查看 BatchNorm 文档来了解更多使用方法，例如如何在训练时使用全局平均的均值和方差。\n",
    "\n",
    "## 扫码直达 [ 讨论区 ](https://discuss.gluon.ai/t/topic/1254)\n",
    "\n",
    "![](../img/qr_batch-norm-gluon.svg)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}